{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## librerías\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "\n",
    "gpu=\"0\"\n",
    "\n",
    "if gpu:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu #aca se pone nuemro de grafica libre\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'Using GPU: {torch.cuda.get_device_name()}')\n",
    "    print('CUDA Visible devices:',os.getenv('CUDA_VISIBLE_DEVICES'))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Failed to find GPU, using CPU instead.\")\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2 \n",
    "import glob\n",
    "\n",
    "## Pytorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#### Modelo\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    #binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),\n",
    "            'aspect_ratio': np.float32(w)/h, \n",
    "            'extent': np.float32(cv2.contourArea(contour))/rect_area,\n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "# function to get tensor of one image\n",
    "def load_image(file_name):\n",
    "    raw = cv2.imread(file_name)\n",
    "    raw = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "    raw = cv2.resize(raw, (128, 128))\n",
    "    raw = raw/255.0\n",
    "    return raw\n",
    "\n",
    "# function to get set of binary image from image loaded\n",
    "def get_binary_image(filenames):\n",
    "    tensores = []\n",
    "    for filename in filenames:\n",
    "        raw = cv2.imread(filename)\n",
    "        raw = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        raw = cv2.resize(raw, (128, 128))\n",
    "        raw = raw/255.0\n",
    "        raw = raw.astype(np.uint8)\n",
    "        tensores.append(raw)\n",
    "    return tensores\n",
    "\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img    \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')\n",
    "        \n",
    "        ## Calcular el aspect ratio de los poros\n",
    "        aspect_ratio = get_item(contour_features, key='aspect_ratio')\n",
    "\n",
    "        ## Número de poros\n",
    "        npores = np.shape(areas)[0]\n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro), np.mean(eq_diameter), np.mean(aspect_ratio), npores]\n",
    "        \n",
    "        descriptors.append(descriptor)       \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "## Reorganizar atributos geométricos\n",
    "def organize_geometric_atributes(dataset):\n",
    "    attributes = []\n",
    "    for i in range(len(dataset)):\n",
    "        attributes.append([dataset['area'].to_numpy()[i],dataset['perimetro'].to_numpy()[i],dataset['intersticio'].to_numpy()[i],dataset['poros'].to_numpy()[i]])\n",
    "\n",
    "    return attributes\n",
    "\n",
    "def get_pores_features(mask):    \n",
    "    ## Calcular atributos geométricos\n",
    "    atrs = get_contours_and_features(mask)\n",
    "    ## lista con los poros\n",
    "    pores = []\n",
    "    for pore in atrs:\n",
    "        ## centro de masa del poro\n",
    "        cx = pore['center_of_mass'][0]\n",
    "        cy = pore['center_of_mass'][1]\n",
    "        ## area del poro\n",
    "        area = pore['area']\n",
    "        ## perimetro del poro\n",
    "        perimeter = pore['perimeter']\n",
    "        ## diametro equivalente del poro\n",
    "        eq_diameter = pore['equivalent_diameter']\n",
    "\n",
    "        pores.append([cx,cy,area,perimeter,eq_diameter])\n",
    "        \n",
    "    ## convertir a dataframe\n",
    "    pores_df = pd.DataFrame(pores,columns=['cx','cy','area','perimeter','eq_diameter'])\n",
    "    \n",
    "    ## drop filas con valores nulos y areas iguals a cero\n",
    "    pores_df = pores_df.dropna()\n",
    "    pores_df = pores_df[pores_df['area'] != 0]\n",
    "\n",
    "    ## drop filas con valores nulos y areas iguals a cero\n",
    "    pores_df = pores_df.dropna()\n",
    "    pores_df = pores_df[pores_df['area'] != 0]\n",
    "\n",
    "\n",
    "    ## extraer la localización de los poros en dataframe aparte\n",
    "    pores_location = pores_df[['cx','cy']]\n",
    "\n",
    "    ## extraer features a parte\n",
    "    pores_features = pores_df[['area','perimeter','eq_diameter']]\n",
    "\n",
    "\n",
    "    return pores_features, pores_location\n",
    "\n",
    "def get_routes_dataset(rutas_dataset):\n",
    "    ## Separar rutas\n",
    "    mask_list = []\n",
    "    image_list = []\n",
    "    for ruta in rutas_dataset:    \n",
    "        ruta_list = ruta.split('/')       \n",
    "        clase = ruta_list[6]\n",
    "        number = ruta_list[7]\n",
    "        tipo = ruta_list[8]\n",
    "        name = ruta_list[9].split('.')[0]\n",
    "        \n",
    "        if tipo == 'train':\n",
    "            image_list.append([name,ruta,clase,number])\n",
    "        elif tipo == 'mask_bin':\n",
    "            mask_list.append([name,ruta,clase,number])\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    mask_pd = pd.DataFrame(mask_list,columns=['name','route_mask','label','number']).sort_values(by='name')\n",
    "    image_pd = pd.DataFrame(image_list,columns=['name','route_image','label','number']).sort_values(by='name')\n",
    "\n",
    "    routes_dataset = image_pd.merge(mask_pd,on=['name','label','number'],how='left')\n",
    "\n",
    "    routes_dataset.dropna(inplace=True)\n",
    "\n",
    "    routes_dataset = routes_dataset.sample(frac = 1)\n",
    "\n",
    "    return routes_dataset\n",
    "\n",
    "def split_dataset(routes_dataset):\n",
    "    ## Establecer el porcentaje de separación\n",
    "    thold1 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label==0])))\n",
    "    thold2 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label==1])))\n",
    "    thold3 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label==2])))\n",
    "\n",
    "    ## Separar por clases para entrenamiento\n",
    "    train_cu1 = routes_dataset[routes_dataset.label == 0][0:thold1]\n",
    "    train_cu2 = routes_dataset[routes_dataset.label == 1][0:thold2]\n",
    "    train_cu3 = routes_dataset[routes_dataset.label == 2][0:thold3]\n",
    "\n",
    "    ## tomar las demás imágenes para test\n",
    "    test_cu1 = routes_dataset[routes_dataset.label == 0][thold1:]\n",
    "    test_cu2 = routes_dataset[routes_dataset.label == 1][thold2:]\n",
    "    test_cu3 = routes_dataset[routes_dataset.label == 2][thold3:]\n",
    "\n",
    "\n",
    "    ## Constuir un solo dataset de training\n",
    "    train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "    ## Construir un solo dataset de test\n",
    "    test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3]).sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "    ## Cantidad de muestras por clase\n",
    "    print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "    print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "    print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def image_to_grapph(mask_route,max_diff = 0.2):\n",
    "    ## cargar máscara\n",
    "    mask = get_binary_image([mask_route])[0]    \n",
    "\n",
    "    ## cargar features from mask\n",
    "    pores_features, pores_location = get_pores_features(mask)\n",
    "\n",
    "    ## Definir nodos de un grafo usando pytorch geometric\n",
    "    from torch_geometric.data import Data\n",
    "\n",
    "    ## definir nodos\n",
    "    nodes = torch.tensor(pores_features.to_numpy(),dtype=torch.float)\n",
    "\n",
    "    ## definir aristas a partir de similitud entre nodos\n",
    "    edges = []\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1,len(nodes)):\n",
    "            ## diferencia\n",
    "            diff = torch.mean(torch.abs(nodes[i] - nodes[j])/torch.abs(nodes[i] + nodes[j]))\n",
    "            ## añadir arista si la diferencia es menor a 0.2\n",
    "            if diff < max_diff:\n",
    "                edges.append([i,j])\n",
    "            \n",
    "    edges = torch.tensor(edges).t().contiguous()\n",
    "\n",
    "    ## definir grafo\n",
    "    data = Data(x=nodes, edge_index=edges)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_routes_dataset_regression(rutas_dataset):\n",
    "    ## Separar rutas\n",
    "    ## /home/Data/Datasets/Micrografías macroproperties/Segmentaciones/MF1/1/Mask/20221026_115804_jpg.rf.552cf2129947708f34806dca73441f72.jpg\n",
    "    mask_list = []\n",
    "    image_list = []\n",
    "    electro_active_area = []\n",
    "    retained_mass = []\n",
    "    electro_deposed_mass = []\n",
    "    \n",
    "    for ruta in rutas_dataset:    \n",
    "        ruta_list = ruta.split('/')       \n",
    "        clase = ruta_list[6]\n",
    "        number = ruta_list[7]\n",
    "        tipo = ruta_list[8]\n",
    "        name = ruta_list[9].split('.jpg')[0]      \n",
    "        \n",
    "            \n",
    "        if clase == 'MF1':\n",
    "            if number == '1':\n",
    "                electro_deposed_mass = 16.85\n",
    "                electro_active_area = 674.15\n",
    "                retained_mass = 91.09                \n",
    "            elif number == '2':\n",
    "                electro_deposed_mass = 16.92\n",
    "                electro_active_area = 650.12\n",
    "                retained_mass = 90.54     \n",
    "            elif number == '3':\n",
    "                electro_deposed_mass = 16.78\n",
    "                electro_active_area = 646.78\n",
    "                retained_mass = 91.06     \n",
    "            elif number == '4':\n",
    "                electro_deposed_mass = 16.78\n",
    "                electro_active_area = 662.33\n",
    "                retained_mass = 90.46     \n",
    "            else:\n",
    "                None\n",
    "        #------------------------------------------------------\n",
    "        elif clase == 'MF2':\n",
    "            if number == '1':\n",
    "                electro_deposed_mass = 12.55\n",
    "                electro_active_area = 941.7\n",
    "                retained_mass = 94.42     \n",
    "            elif number == '2':\n",
    "                electro_deposed_mass = 12.65\n",
    "                electro_active_area = 912.6\n",
    "                retained_mass = 93.67\n",
    "            elif number == '3':\n",
    "                electro_deposed_mass = 12.60\n",
    "                electro_active_area = 915.24\n",
    "                retained_mass = 93.65\n",
    "            elif number == '4':\n",
    "                electro_deposed_mass = 12.58\n",
    "                electro_active_area = 925.4    \n",
    "                retained_mass = 93.64     \n",
    "            else:\n",
    "                None\n",
    "        # -------------------------------------------------------  \n",
    "        elif clase == 'MF3':\n",
    "            if number == '1':\n",
    "                electro_deposed_mass = 8.09\n",
    "                electro_active_area = 1225.2\n",
    "                retained_mass = 98.76\n",
    "            elif number == '2':\n",
    "                electro_deposed_mass = 8.10\n",
    "                electro_active_area = 1242.2\n",
    "                retained_mass = 98.76\n",
    "            elif number == '3':\n",
    "                electro_deposed_mass = 8.11\n",
    "                electro_active_area = 1214.5\n",
    "                retained_mass = 97.53\n",
    "            elif number == '4':\n",
    "                electro_deposed_mass = 8.10\n",
    "                electro_active_area = 1220.3\n",
    "                retained_mass = 98.76\n",
    "            else:\n",
    "                None\n",
    "\n",
    "                \n",
    "                \n",
    "        if tipo == 'train':\n",
    "            image_list.append([name,ruta,clase,number,electro_deposed_mass,electro_active_area,retained_mass])\n",
    "        elif tipo == 'Mask':\n",
    "            mask_list.append([name,ruta,clase,number,electro_deposed_mass,electro_active_area,retained_mass])\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    mask_pd = pd.DataFrame(mask_list,\n",
    "                           columns=['name','route_mask','label','number','mass_electrodeposited','area_electroactive','retained_mass']).sort_values(by='name')\n",
    "    image_pd = pd.DataFrame(image_list,\n",
    "                            columns=['name','route_image','label','number','mass_electrodeposited','area_electroactive','retained_mass']).sort_values(by='name')\n",
    "\n",
    "    routes_dataset = image_pd.merge(mask_pd,on=['name','label','number','mass_electrodeposited','area_electroactive','retained_mass'],how='left')\n",
    "\n",
    "    routes_dataset.dropna(inplace=True)\n",
    "\n",
    "    routes_dataset = routes_dataset.sample(frac = 1)\n",
    "\n",
    "    return routes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "## ejemplo de estructura de ruta: /home/Data/Datasets/Micrografías macroproperties/Segmentaciones/MF1/1/Mask/20221026_115804_jpg.rf.552cf2129947708f34806dca73441f72.jpg\n",
    "rutas_dataset  = glob.glob('../../../Datasets/Micrografías_macroproperties/Segmentaciones/*/*/*/*.jpg')\n",
    "\n",
    "routes_dataset = get_routes_dataset_regression(rutas_dataset)\n",
    "\n",
    "## replace label names for numbers\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "routes_dataset['label'] = routes_dataset['label'].replace(['MF1','MF2','MF3'],[0,1,2])\n",
    "\n",
    "routes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_route = routes_dataset['route_mask'].to_numpy()[0]\n",
    "\n",
    "## Constuir una matriz de atributos geométricos de la imagen\n",
    "mask = get_binary_image([mask_route])[0]\n",
    "\n",
    "pores_features, pores_location = get_pores_features(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seleccionar una imagen aleatoria\n",
    "idx = 0\n",
    "mask_route = routes_dataset['route_mask'].to_numpy()[idx]\n",
    "image_route = routes_dataset['route_image'].to_numpy()[idx]\n",
    "\n",
    "## plot mascara y original\n",
    "mask = cv2.imread(mask_route)\n",
    "image = cv2.imread(image_route)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## graph for distances\n",
    "## crear grafo\n",
    "G = nx.Graph()\n",
    "\n",
    "## añadir nodos definidos por su posición x,y\n",
    "for i in range(len(pores_location)):\n",
    "    ## node properties\n",
    "    x = pores_location['cx'].to_numpy()[i]\n",
    "    y = pores_location['cy'].to_numpy()[i]\n",
    "    \n",
    "    ## add node\n",
    "    G.add_node(i,pos=(x,y))\n",
    "    \n",
    "## añadir aristas\n",
    "for i in range(len(pores_location)):\n",
    "    for j in range(i+1,len(pores_location)):\n",
    "        ## distancia euclidiana\n",
    "        x1 = pores_location['cx'].to_numpy()[i]\n",
    "        y1 = pores_location['cy'].to_numpy()[i]\n",
    "        x2 = pores_location['cx'].to_numpy()[j]\n",
    "        y2 = pores_location['cy'].to_numpy()[j]\n",
    "        dist = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        ## añadir arista si la distancia es menor a 10\n",
    "        if dist < 128*0.2:\n",
    "            G.add_edge(i,j,weight=dist)\n",
    "            \n",
    "## dibujar grafo sobre la imagen original \n",
    "plt.figure(figsize=(10,10))\n",
    "## redimensionar imagen para que se ajuste al grafo 128x128\n",
    "image = cv2.resize(image,(128,128))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "## dibujar nodos\n",
    "pos = nx.get_node_attributes(G,'pos')\n",
    "nx.draw(G,pos,node_size=50,node_color='red',with_labels=False,edge_color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graphgym\n",
    "## visualizar grafo\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "mask_route = routes_dataset['route_mask'].to_numpy()[0]\n",
    "\n",
    "data = image_to_grapph(mask_route)\n",
    "\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(5,5))\n",
    "nx.draw(G, pos, node_size=50, node_color='red', with_labels=False, edge_color='blue')\n",
    "plt.show()\n",
    "plt.tight_layout()    \n",
    "print(data.num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFsImagesDataset(Dataset):\n",
    "    def __init__(self, routes_dataframe):\n",
    "        self.routes_dataframe = routes_dataframe\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.labels = []\n",
    "        self.electro_deposed_mass = []\n",
    "        self.electro_active_area = []\n",
    "        self.retained_mass = []\n",
    "        self.graphs = []\n",
    "        self.transform_mask = transforms.Compose([\n",
    "            transforms.Grayscale(), # Ensure the image is grayscale\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomRotation(180),       \n",
    "            transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.transform_image = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "            #data_augmentation,\n",
    "            transforms.Grayscale(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomRotation(180),            \n",
    "            transforms.ToTensor(),\n",
    "        ])       \n",
    "        \n",
    "        # Recursively gather all image paths in the folder and subfolders\n",
    "        for idx in range(len(self.routes_dataframe)):\n",
    "            mask_route = self.routes_dataframe['route_mask'].to_numpy()[idx]\n",
    "            image_route = self.routes_dataframe['route_image'].to_numpy()[idx]\n",
    "            clase = torch.tensor(self.routes_dataframe['label'].to_numpy()[idx])\n",
    "            electro_deposed_mass = torch.tensor(self.routes_dataframe['mass_electrodeposited'].to_numpy()[idx])\n",
    "            electro_active_area = torch.tensor(self.routes_dataframe['area_electroactive'].to_numpy()[idx])\n",
    "            retained_mass = torch.tensor(self.routes_dataframe['retained_mass'].to_numpy()[idx])\n",
    "            \n",
    "            self.image_paths.append(image_route)\n",
    "            self.mask_paths.append(mask_route)\n",
    "            self.labels.append(clase)\n",
    "            self.electro_deposed_mass.append(electro_deposed_mass)\n",
    "            self.electro_active_area.append(electro_active_area)\n",
    "            self.retained_mass.append(retained_mass)\n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ## leer imagen, más y etiqueta\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        image_label = self.labels[idx]\n",
    "        image_electro_deposed_mass = self.electro_deposed_mass[idx]\n",
    "        image_electro_active_area = self.electro_active_area[idx]\n",
    "        image_retained_mass = self.retained_mass[idx]\n",
    "        \n",
    "        ## cargar imagen y máscara y aplicar transformaciones\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "        ## obtener propiedades de los poros de la máscara\n",
    "        graph = image_to_grapph(mask_path,max_diff = 0.2)\n",
    "        \n",
    "                    \n",
    "        return image, mask, graph, image_label, image_electro_deposed_mass, image_electro_active_area, image_retained_mass\n",
    "\n",
    "def collate_fn(batch):\n",
    "    import torch_geometric\n",
    "    images, masks, graphs, labels, image_electro_deposed_mass, image_electro_active_area, image_retained_mass = zip(*batch)\n",
    "    \n",
    "    # Convert lists to tensors if necessary\n",
    "    images = torch.stack(images)\n",
    "    masks = torch.stack(masks)\n",
    "    labels = torch.tensor(labels)\n",
    "    image_electro_deposed_mass = torch.tensor(image_electro_deposed_mass)\n",
    "    image_electro_active_area = torch.tensor(image_electro_active_area)\n",
    "    image_retained_mass = torch.tensor(image_retained_mass)\n",
    "    \n",
    "    # Batch the graphs using torch_geometric's batch function\n",
    "    graphs = torch_geometric.data.Batch.from_data_list(graphs)\n",
    "    \n",
    "    return images, masks, graphs, labels, image_electro_deposed_mass, image_electro_active_area, image_retained_mass\n",
    "    \n",
    "## split dataset into train and test 80-20\n",
    "train_df, test_df = split_dataset(routes_dataset)\n",
    "\n",
    "train_dataset = MFsImagesDataset(train_df)\n",
    "test_dataset = MFsImagesDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask, graph, label, edm, eaa, rm in train_loader:\n",
    "    print('Image shape:', image.shape)\n",
    "    print('Mask shape:', mask.shape)\n",
    "    print('label')\n",
    "    print('Graph information:')\n",
    "    print('Number of nodes:', graph.num_nodes)\n",
    "    print('Number of edges:', graph.num_edges)\n",
    "    print('Number of features:', graph.num_features)\n",
    "    print('Number of edge features:', graph.num_edge_features)\n",
    "    print('Number of node features:', graph.num_node_features)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelo de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/graph-convolutional-networks-introduction-to-gnns-24b3f60d6c95\n",
    "#https://github.com/pyg-team/pytorch_geometric\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "## Graph convoluitonal network for classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        self.classifier = nn.Linear(out_channels, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):        \n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        #print(f'After conv1 x shape: {x.shape}')\n",
    "        \n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        #print(f'After conv2 x shape: {x.shape}')# Initialize the model\n",
    "        \n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        #print(f'After conv3 x shape: {x.shape}')\n",
    "        \n",
    "        x = torch.mean(x, dim=0)  # Example: mean pooling\n",
    "        #print(f'After pooling x shape: {x.shape}')\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x \n",
    "        \n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(in_channels=3, hidden_channels=64, out_channels=64, num_classes=3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Training loop\n",
    "model.train()\n",
    "train_loss = 0\n",
    "torch.set_grad_enabled(True)\n",
    "for epoch in range(200):\n",
    "    time_init = time.time()\n",
    "    for data in train_loader:\n",
    "        image, mask, graph, label, edm, eaa, rm = data\n",
    "        x = graph.x\n",
    "        edge_index = graph.edge_index\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, edge_index)\n",
    "        # argmax\n",
    "        #pred = torch.argmax(pred, dim=-1)\n",
    "        label = label.squeeze()\n",
    "        \n",
    "        ## create one hot encoding\n",
    "        label = F.one_hot(label, num_classes=3)\n",
    "        #pred = F.one_hot(pred, num_classes=3)\n",
    "        \n",
    "        ## turn to int tensor\n",
    "        label = label.type(torch.FloatTensor)\n",
    "        pred = pred.type(torch.FloatTensor)       \n",
    "        \n",
    "        # Ensure labels are LongTensor and shape is correct\n",
    "        loss = nn.CrossEntropyLoss()(pred, label)\n",
    "        \n",
    "        # Backpropagation        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    time_out = time.time()\n",
    "    print(f'Epoch {epoch+1}/{200}, Loss: {train_loss:.4f}, Time: {time_out-time_init:.2f} s')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model\n",
    "torch.save(model.state_dict(), 'Models/model_gnn_2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
